{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fae71c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "from autograd import grad\n",
    "from autograd import hessian\n",
    "import scipy.optimize as opt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1590a7a",
   "metadata": {},
   "source": [
    "## 2-nests. Nest A and Nest B both have two products, respectively. Namely, $\\{1,2\\} \\in A$, and $\\{3,4\\} \\in B$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230b1103",
   "metadata": {},
   "source": [
    "## Data Generating Process\n",
    "\n",
    "- Utility function\n",
    "\n",
    "$$\n",
    "U_{nj}  = -\\beta_1 \\frac{price_j}{income_{n}}+ \\beta_2 quality_{j} + \\epsilon_{nj}\n",
    "$$\n",
    "- Four alternatives\n",
    "- Two nests in which there are two alternatives\n",
    "- 100 consumers\n",
    "- $\\epsilon_{nj}$ follows GEV distribution with parameters $<\\lambda_1, \\lambda_2>$\n",
    "- $\\lambda_1 = 1.2$\n",
    "- $\\lambda_2 = 1.5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3576514f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/vq/y8sw0dx95kg8d24dbz5s_kt80000gn/T/ipykernel_83334/1180628053.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# User-level characteristics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtrue_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlda1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlda2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mincome\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhigh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0muid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "k1 = 2\n",
    "k2 = 2\n",
    "K = 2\n",
    "\n",
    "N = 100\n",
    "\n",
    "\n",
    "b1 = -1.4\n",
    "b2 = .8\n",
    "lda1 = 1.2\n",
    "lda2 = 1.5\n",
    "\n",
    "\n",
    "# User-level characteristics\n",
    "true_params = np.array([b1,b2,lda1,lda2])\n",
    "income = np.random.uniform(low = 2,high = 5, size = N)\n",
    "uid = np.arange(N)\n",
    "user = pd.DataFrame(data = np.concatenate([uid.reshape(-1,1),income.reshape(-1,1)],axis=1),columns = ['uid','income'])\n",
    "\n",
    "# Product-level characteristics\n",
    "price = abs(np.random.normal(scale = 2,loc=1.3, size = k1 + k2).reshape(-1,1))\n",
    "quality = abs(np.random.normal(scale = 2,loc =3.2, size = k1 + k2).reshape(-1,1))\n",
    "\n",
    "gid = np.arange(k1+k2)\n",
    "goods = pd.DataFrame(data = np.concatenate([gid.reshape(-1,1),price, quality],axis=1),columns = ['gid','price','quality'])\n",
    "\n",
    "\n",
    "# Merged dataset, shape = (N * K,2)\n",
    "data = user.merge(goods, how = 'cross')\n",
    "data['nest'] = 0\n",
    "data.loc[data.query('gid<2').index,'nest'] = 1\n",
    "data.loc[data.query('gid>=2').index,'nest'] = 2\n",
    "data['p/i'] = data['price']/data['income']\n",
    "dataset = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2748,
   "id": "b56a51fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample(params):\n",
    "    \"\"\"\n",
    "    Params: params---> all paramters drew by certain criterions or randomly.\n",
    "    Return: P_j ---> predicted probability for each choice for each consumer.\n",
    "    Description: This function uses for generating true choice probability under true parameters\n",
    "    \"\"\"\n",
    "    b = params[:2]\n",
    "    lda = params[2:]\n",
    "    V = X.reshape(N,4,2).dot(b.reshape(-1,1))\n",
    "    V = V - V.mean(axis=1).reshape(N,1,1)\n",
    "    w = V.reshape(N,2,2).mean(axis=2)\n",
    "    y = V.reshape(N,2,2) - w.reshape(N,2,1)\n",
    "    Ink = np.log(np.exp(y/(lda.reshape(-1,1))).sum(axis=2))\n",
    "    Ink_lda = Ink * lda\n",
    "    Pk = np.exp(w + Ink_lda)\n",
    "    Pk = Pk/Pk.sum(axis=1,keepdims=True)\n",
    "    P_j_given_k = np.exp(V.reshape(N,2,2)/(lda.reshape(-1,1)))\n",
    "    P_j_given_k = P_j_given_k/P_j_given_k.sum(axis=2,keepdims=True)\n",
    "    P_j = Pk.reshape(N,-1,1) * P_j_given_k \n",
    "    return P_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2749,
   "id": "57399f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_choice(p_draw):\n",
    "    \"\"\"\n",
    "    Params: p_draw ----> drawing probabilities\n",
    "    Return: predicted choice under p_draw\n",
    "    Description: This function predicts each consumer's choice when using true parameters\n",
    "    \"\"\"\n",
    "    true_choice = np.zeros(N)\n",
    "    for i in range(len(true_choice)):\n",
    "        true_choice[i] = (np.random.choice((dataset['gid'].values.reshape(N,-1))[i],p = (p_draw.reshape(N,-1))[i]))\n",
    "    true_choice = true_choice.astype(int)\n",
    "    choice_set = np.zeros(shape=(N,4))\n",
    "    for i in range(len(true_choice)):\n",
    "        choice_set[i, true_choice[i]] = 1\n",
    "    return choice_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2750,
   "id": "cd98a11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = dataset.sort_values(by = ['uid','gid'])\n",
    "\n",
    "X = np.array(dataset[['p/i','quality']].values)\n",
    "p_draw =  generate_sample(true_params)\n",
    "observed_choice = get_choice(p_draw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2751,
   "id": "1e7a3ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lln(params):\n",
    "    '''\n",
    "    Params: params ----> all parameters in the model\n",
    "    Return: Log-likelihood function\n",
    "    Description: This function calculates the log-likelihood under a set of parameters using sequential method (conditional probability)\n",
    "    '''\n",
    "#     params = np.exp(params)\n",
    "    b = params[:2]\n",
    "    lda = params[2:]\n",
    "    V = X.reshape(N,4,2).dot(b.reshape(-1,1))\n",
    "    V = V - V.mean(axis=1).reshape(N,1,1)\n",
    "    w = V.reshape(N,2,2).mean(axis=2)\n",
    "    y = V.reshape(N,2,2) - w.reshape(N,2,1)\n",
    "    Ink = np.log(np.exp(y/(lda.reshape(-1,1))).sum(axis=2))\n",
    "    Ink_lda = Ink * lda\n",
    "    Pk = np.exp(w + Ink_lda)\n",
    "    Pk = Pk/Pk.sum(axis=1,keepdims=True)\n",
    "    P_j_given_k = np.exp(V.reshape(N,2,2)/(lda.reshape(-1,1)))\n",
    "    P_j_given_k = P_j_given_k/P_j_given_k.sum(axis=2,keepdims=True)\n",
    "    P_j = Pk.reshape(N,-1,1) * P_j_given_k\n",
    "    \n",
    "    return -np.sum(np.log(P_j).reshape(N,-1)* observed_choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2752,
   "id": "e8e7c925",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ll(params):\n",
    "        '''\n",
    "    Params: params ----> all parameters in the model\n",
    "    Return: Log-likelihood function\n",
    "    Description: This function calculates the log-likelihood under a set of parameters using MLE\n",
    "    '''\n",
    "    b = params[:2]\n",
    "    lda = params[2:]\n",
    "    V = X.reshape(N,4,2).dot(b.reshape(-1,1))\n",
    "    V = V - V.mean(axis=1).reshape(N,1,1)\n",
    "    e_p = np.exp(V.reshape(N,2,2)/(lda.reshape(-1,1)))\n",
    "    ep_sum = e_p.sum(axis=2)\n",
    "    P_j = e_p * (ep_sum**(lda-1)).reshape(N,2,1)/(((ep_sum**(lda)).sum(axis=1)).reshape(N,1,1)) \n",
    "    return -np.sum(np.log(P_j).reshape(N,-1)* observed_choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2753,
   "id": "d7ff31bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Log-likelihood using sequential method:- 113.79051134754229\n",
      "True Log-likelihood using MLE method:- 113.79051134754229\n",
      "\n",
      " Therefore, two methods result in the same log-likelihood at the true parameters\n"
     ]
    }
   ],
   "source": [
    "#### Verifying our data\n",
    "print('True Log-likelihood using sequential method:-', lln(true_params))\n",
    "print('True Log-likelihood using MLE method:-', get_ll(true_params))\n",
    "print('\\n Therefore, two methods result in the same log-likelihood at the true parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814ea516",
   "metadata": {},
   "source": [
    "## In this initial values, both methods converge to the true solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2778,
   "id": "90402197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------\n",
      "Sequential method estimates:\n",
      "Estiamted log-likelihood =  -113.49761668287528\n",
      "Initial parameters =  [0.5 0.9 0.1 0.1]\n",
      "Predicted parameters =  [-1.39119947  1.02120133  1.3017994   1.49873968]\n",
      "True parameters =  [-1.4  0.8  1.2  1.5]\n",
      "---------------------\n",
      "MLE estimates:\n",
      "Estiamted log-likelihood =  -113.4976166828102\n",
      "Initial parameters =  [0.5 0.9 0.1 0.1]\n",
      "Predicted parameters =  [-1.39119751  1.02119958  1.3017973   1.4987374 ]\n",
      "True parameters =  [-1.4  0.8  1.2  1.5]\n"
     ]
    }
   ],
   "source": [
    "params = np.array([0.5,0.9,0.1,.1])\n",
    "res = opt.minimize(lln,x0=params,method = 'L-BFGS-B')\n",
    "print('---------------------')\n",
    "print('Sequential method estimates:')\n",
    "print('Estiamted log-likelihood = ', -res.fun)\n",
    "print('Initial parameters = ', params)\n",
    "print('Predicted parameters = ', res.x)\n",
    "print('True parameters = ', true_params)\n",
    "\n",
    "\n",
    "\n",
    "res = opt.minimize(get_ll,x0=params,method = 'L-BFGS-B')\n",
    "print('---------------------')\n",
    "print('MLE estimates:')\n",
    "print('Estiamted log-likelihood = ', -res.fun)\n",
    "print('Initial parameters = ', params)\n",
    "print('Predicted parameters = ', res.x)\n",
    "print('True parameters = ', true_params)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ca4877",
   "metadata": {},
   "source": [
    "## However, under this initial vector, Sequential method converges to the true value while the MLE converges to a local min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2821,
   "id": "68681b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------\n",
      "Sequential method estimates:\n",
      "Estiamted log-likelihood =  -113.49761668210584\n",
      "Initial parameters =  [-2.55289528  2.63527582 -5.036244   -0.59738734]\n",
      "Predicted parameters =  [-1.39117254  1.0211664   1.30175949  1.49871583]\n",
      "True parameters =  [-1.4  0.8  1.2  1.5]\n",
      "---------------------\n",
      "MLE estimates:\n",
      "Estiamted log-likelihood =  -114.21229265760132\n",
      "Initial parameters =  [-2.55289528  2.63527582 -5.036244   -0.59738734]\n",
      "Predicted parameters =  [-0.01541516 -0.23023235 -0.16775621 -0.07156722]\n",
      "True parameters =  [-1.4  0.8  1.2  1.5]\n"
     ]
    }
   ],
   "source": [
    "params = np.random.normal(size=4,scale=2)\n",
    "\n",
    "res = opt.minimize(lln,x0=params,method = 'L-BFGS-B')\n",
    "print('---------------------')\n",
    "print('Sequential method estimates:')\n",
    "print('Estiamted log-likelihood = ', -res.fun)\n",
    "print('Initial parameters = ', params)\n",
    "print('Predicted parameters = ', res.x)\n",
    "print('True parameters = ', true_params)\n",
    "\n",
    "\n",
    "\n",
    "res = opt.minimize(get_ll,x0=params,method = 'L-BFGS-B')\n",
    "print('---------------------')\n",
    "print('MLE estimates:')\n",
    "print('Estiamted log-likelihood = ', -res.fun)\n",
    "print('Initial parameters = ', params)\n",
    "print('Predicted parameters = ', res.x)\n",
    "print('True parameters = ', true_params)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0cf0f0",
   "metadata": {},
   "source": [
    "# Archived\n",
    "## Archived data generating process\n",
    "Here I comment out another method of DGP which I ever used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31691c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DGP 1\n",
    "\n",
    "# k1 = 2\n",
    "# k2 = 2\n",
    "# K = 2\n",
    "# ## 2000 consumers\n",
    "# N = 2000\n",
    "\n",
    "\n",
    "# b1 = -1.4\n",
    "# b2 = .8\n",
    "# lda1 = 1.2\n",
    "# lda2 = 1.5\n",
    "# params = np.array([b1,b2,lda1,lda2])\n",
    "# true_params = np.array([b1,b2,lda1,lda2])\n",
    "\n",
    "# income = np.random.uniform(low = 1,high = 3, size = N)\n",
    "# uid = np.arange(N)\n",
    "# user = pd.DataFrame(data = np.concatenate([uid.reshape(-1,1),income.reshape(-1,1)],axis=1),columns = ['uid','income'])\n",
    "\n",
    "\n",
    "# price = abs(np.random.normal(scale = 2,loc=1.3, size = k1 + k2).reshape(-1,1))\n",
    "# quality = abs(np.random.normal(scale = 2,loc =3.2, size = k1 + k2).reshape(-1,1))\n",
    "# gid = np.arange(k1+k2)\n",
    "\n",
    "\n",
    "# goods = pd.DataFrame(data = np.concatenate([gid.reshape(-1,1),price, quality],axis=1),columns = ['gid','price','quality'])\n",
    "\n",
    "\n",
    "# data = user.merge(goods, how = 'cross')\n",
    "# data['nest'] = 0\n",
    "# data.loc[data.query('gid<2').index,'nest'] = 1\n",
    "# data.loc[data.query('gid>=2').index,'nest'] = 2\n",
    "# data['p/i'] = data['price']/data['income']\n",
    "# data['v'] = data[['p/i','quality']].dot(params[:2])\n",
    "# data['w'] =  data.groupby(['nest','uid'])['v'].transform('mean')\n",
    "# data['y'] = data['v'] - data['w']\n",
    "# data['lda1'] = lda1\n",
    "# data['lda2'] = lda2\n",
    "# data['lda'] = 0.\n",
    "# data.loc[data.query('nest == 1').index,'lda'] = data['lda1']\n",
    "# data.loc[data.query('nest == 2').index,'lda'] = data['lda2']\n",
    "\n",
    "# def calc_i(df):\n",
    "#     return np.log(np.exp(df['y']/df['lda']).sum())\n",
    "\n",
    "# Ink = data.groupby(['nest','uid']).apply(calc_i).reset_index().rename({0:'I'},axis=1)\n",
    "# data = data.merge(Ink)\n",
    "# data['lda_i'] = data['lda'] * data['I']\n",
    "\n",
    "# ee1 = np.random.gumbel(scale = lda1, size = N * k1)\n",
    "# ee2 = np.random.gumbel(scale = lda2, size = N * k2)\n",
    "# dataset = data.sort_values(by = ['nest','uid'])\n",
    "# dataset['ee'] = np.concatenate([ee1,ee2])\n",
    "# e = np.random.gumbel(scale = 1, size = N*K)\n",
    "# ek = pd.DataFrame(np.concatenate([np.repeat(uid,2).reshape(-1,1),np.array([0.,1.]*N).reshape(-1,1),e.reshape(-1,1)],axis=1),columns = ['uid','nest','e'])\n",
    "# ek = ek.sort_values(by = ['nest','uid'])\n",
    "# dataset['e'] = np.concatenate([np.repeat(ek['e'][:N],2), np.repeat(ek['e'][N:],2)]) \n",
    "# dataset['xi']=0\n",
    "# dataset[dataset['nest'] == 1].loc[:,'xi'] = np.random.gumbel(0,1)\n",
    "# dataset[dataset['nest'] == 2].loc[:,'xi'] = np.random.gumbel(0,1)\n",
    "# dataset['u'] = dataset['y'] + dataset['w'] +dataset['lda_i'] + dataset['e'] + dataset['xi']\n",
    "# dataset['max_u'] = dataset.groupby(['uid'])['u'].transform(max)\n",
    "# outcome = dataset.query('(max_u == u)' )[['uid','gid']].rename({'gid':'outcome'},axis=1)\n",
    "# dataset = dataset.merge(outcome)\n",
    "\n",
    "# X = np.array(dataset[['p/i','quality']].values)\n",
    "# dataset['choice'] = 0\n",
    "# dataset.loc[dataset.query('outcome == gid').index,'choice']=1\n",
    "# choice = np.array(dataset['choice'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
